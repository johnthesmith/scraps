# Вступление

Считаю, что вопросы надежности и безопасности искусственного интеллекта 
становятся определяющими для его применения в ответственных областях. Вопреки 
распространенному мнению о принципиальной непредсказуемости нейросетей, 
необходимо различать два независимых аспекта их работы.

О повторяемости. Как показано в [предыдущей статье](https://github.com/johnthesmith/scraps/blob/main/ru/nn-determinism.md), 
любая нейросеть должна быть детерминирована: при фиксированных входных данных, 
весах и условиях исполнения результат обязан быть неизменным. Недетерминизм — 
это всегда ошибка реализации (баг), недопустимый в промышленных системах уровней 
mission-critical и business-critical.

О корректности результатов. Однако детерминизм сам по себе ничего не говорит о 
том, верен ли полученный результат. Далее рассматриваем способы проверки 
результата.



# Способы проверки корректности результатов

Все методы верификации можно разделить на три категории по источнику эталона 
истины:

1. [Человек](#человек)
2. [Эксперимент](#эксперимент)
3. [Формальная спецификация или конечный алгоритм](#формальная-спецификация-или-конечный-алгоритм)
4. [Нейросеть](#нейросеть)
5. [Смешанный подход](#смешанный-подход)



## Человек

Человек выступает прямым источником истины. Эксперт оценивает результат, исходя 
из собственного знания о том, каким должен быть правильный ответ. Для снижения 
субъективности применяется коллективная или коллегиальная оценка. Да, человек 
может ошибаться. Однако человечество дожило до текущего момента, опираясь именно 
на этот способ оценки — значит, как минимум он проверен временем. И 
принципиально ничего лучше пока не придумано.



## Эксперимент

Эксперимент — это проверка нейросети самой реальностью. Результат сверяется с 
тем, что происходит в физическом мире. Это наиболее достоверный способ 
верификации, поскольку реальность не обсуждается и не ошибается. Ограничение: 
эксперимент часто невозможен до начала реальной эксплуатации либо слишком дорог, 
опасен или невозможен в реалтайме.



## Формальная спецификаия или конечный алогритм

Этот способ опирается на заранее известное формализованное знание о правильном 
результате, наличие функциональной зависимости или наличие статистики реального 
мира.

Часто мы не можем заранее вычислить правильный ответ — это заняло бы слишком 
много времени. Но когда эвристический ответ уже получен от нейросети, проверить 
его конечным алгоритмом оказывается вполне возможно.

Преимущество подхода — объективность и воспроизводимость. Ограничение 
— применим только там, где правильный ответ поддается формализации.




## Нейросеть

Переходим к опасным способам проверки.

Использование другой нейросети в качестве эталона — распространенный, но 
ошибочный подход. Он основан на ложном предположении, что если одна сеть 
достаточно хороша, то она может служить мерилом для другой.

"Эталонная" модель. Берется нейросеть, которую считают более точной (например, 
большего размера или обученная дольше), и ее ответы принимаются за правильные 
при проверке другой сети.

Ансамблевые методы. Усредняются ответы нескольких сетей, и полученное среднее 
считается эталоном для проверки каждой отдельной сети.

Кросс-валидация между архитектурами. Сравниваются ответы сетей разной 
архитектуры, и совпадение интерпретируется как подтверждение правильности.

Проблема всех этих методов в том, что они не дают выхода к истине — только 
сравнивают разные аппроксимации между собой.


## О смешанном подходе

Смешанный подход: результаты алгоритма или человека используются для обучения 
нейросети, которая затем проверяет другую нейросеть.

На первый взгляд допустимо — эталон был внешним. Но ошибка лишь скрыта, а не 
устранена. Почему это недопустимо:

Потеря независимости. Обученная на эталоне нейросеть — это лишь 
аппроксимация, а не сам эталон. Гарантии исходного источника утрачены.

Невозможность верификации границ. Алгоритм или человек давали ответы на конечном 
множестве. Нейросеть экстраполирует на бесконечное пространство, и неизвестно, 
где ее ответы расходятся с исходным эталоном.

Циркулярность. Проверка одной аппроксимации через другую — потеря прямой 
связи с первоисточником истины.



## Доказательство некорректности проверки через обученную сеть

1. Пусть \( T \) — истина (оракул) неизвестная нейросети, при этом бесконечно 
сложна и не имеет компактного описания (иначе бы для решения задачи не 
применялась нейросеть).

2. Пусть \( N_1 = Train(T, D_1) \) и \( N_2 = Train(T, D_2) \), где \( D_1 \) и \( D_2 \) — 
конечные выборки из \( T \), причем \( D_1 \neq D_2 \) и \( D_1 \cup D_2 \neq T \).

   Процедура обучения в общем случае не гарантирует, что:
   \[
   \forall x: N_1(x) = T(x)
   \]
   \[
   \forall x: N_2(x) = T(x)
   \]

Каждая нейросеть видела только свой кусок истины и никогда не видела всю \( T \) 
целиком.

3. Рассмотрим проверку \( N_1 \) через \( N_2 \) как требование:
   \[
   \forall x: N_1(x) = N_2(x)
   \]

   Возьмем \( x^* \notin D_1 \cup D_2 \). 
   Для этой точки обе сети дают ответ, не подтвержденный истиной \( T \). 
   При этом \( N_1(x^*) \) может равняться \( N_2(x^*) \), но гарантий, что это значение равно \( T(x^*) \), 
   нет — \( T \) для этой точки неизвестна.

Следовательно, из \( \forall x: N_1(x) = N_2(x) \) **не следует** \( \forall x: N_1(x) = T(x) \).

Даже если N1(x∗)=N2(x∗)N1​(x∗)=N2​(x∗), это может быть совпадение «по случайности» 
или системная ошибка обобщения, а не подтверждение истинного значения.

Совпадение ответов двух нейросетей не является свидетельством 
истинности. Никакая нейросеть не может служить эталоном для другой.


# Вывод

Использовать одну нейросеть для проверки другой — критически небезопасно.

Совпадение ответов не дает никаких гарантий корректности. Обе могут одинаково 
ошибаться в точках, не виденных ни одной из них при обучении. А где именно 
пролегают эти точки и какова истина — неизвестно.

Как показано в [предыдущей статье](https://github.com/johnthesmith/scraps/blob/main/ru/nn-determinism.md), 
детерминированность — необходимое условие надежности, но недостаточное. Для 
`mission-critical` и `business-critical` систем помимо повторяемости результатов 
требуется их проверяемость.

Единственный допустимый эталон — **внешний и независимый**: человек, 
эксперимент, формальная спецификация (производная от человека) или конечный 
алгоритм. Всё остальное — создание иллюзии контроля вместо реальной верификации.

---

PS: я признаю, что проверка одной нейросети другой нейросетью, это компромис 
развития, однако утверждаю, что на большом отрезке времени при высокой сложности 
данная практика приведет либо к медленной деградации или к внезапной катострофе 
эксплуатируемой системы.

Дыры в знаниях `x∗∉D1∪D2x∗∈/D1​∪D2​` никуда не исчезают — они лишь маскируются 
взаимным подтверждением ошибок.
